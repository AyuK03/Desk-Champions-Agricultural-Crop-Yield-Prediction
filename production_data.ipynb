{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashish Singh\\AppData\\Local\\Temp\\ipykernel_8968\\4080736814.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\n",
    "    r\"D:\\OpenHack\\Hackathon Datasets\\Crop Yield Data\\APY_Potato.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Area</th>\n",
       "      <th>Production</th>\n",
       "      <th>Yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADILABAD</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>18</td>\n",
       "      <td>68</td>\n",
       "      <td>3.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ADILABAD</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ADILABAD</td>\n",
       "      <td>2006-07</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ANANTAPUR</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ANANTAPUR</td>\n",
       "      <td>2002-03</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Place      Date       Season Area Production     Yield\n",
       "4   ADILABAD   2000-01  Whole Year    18         68  3.777778\n",
       "5   ADILABAD   2005-06  Whole Year     2         17       8.5\n",
       "6   ADILABAD   2006-07  Whole Year     3         45        15\n",
       "7  ANANTAPUR   2000-01  Whole Year     4         34       8.5\n",
       "8  ANANTAPUR   2002-03  Whole Year     2         17       8.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove first 2 rows and make the 3rd row as header\n",
    "data = data[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashish Singh\\AppData\\Local\\Temp\\ipykernel_8968\\1808912994.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data.iloc[:, 0] = data.iloc[:, 0].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# in first column fill the NaN values with the previous value\n",
    "data.iloc[:, 0] = data.iloc[:, 0].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashish Singh\\AppData\\Local\\Temp\\ipykernel_8968\\2741510801.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data.iloc[:, 1] = data.iloc[:, 1].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# forward fill the second column\n",
    "data.iloc[:, 1] = data.iloc[:, 1].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the rows where 3rd column has NaN values\n",
    "data = data.dropna(subset=[data.columns[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns\n",
    "data.columns = ['Place', 'Date', 'Season', 'Area', 'Production', 'Yield']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove first 2 characters from the 'Place' column\n",
    "data['Place'] = data['Place'].str[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove first character from the place column (cuz only a digit and . was visible)\n",
    "data['Place'] = data['Place'].str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove . from the 'Place' column (inspecting the the other rows in the tail of the dataframe, there was again .)\n",
    "data['Place'] = data['Place'].str.replace('.', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove digits from the 'Place' column\n",
    "data['Place'] = data['Place'].str.replace(r'\\d+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import time\n",
    "\n",
    "cleaned_data = data\n",
    "\n",
    "# get the unique places\n",
    "places = cleaned_data['Place'].unique()\n",
    "\n",
    "# make a list for storing the coordinates\n",
    "coordinates_list = []\n",
    "\n",
    "# for each place get the coordinates\n",
    "for place in places:\n",
    "    url = f\"https://geocode.maps.co/search?q={place}&api_key=65cfa174890c9160700920myo18621b\"\n",
    "    time.sleep(0.5)\n",
    "    response = requests.get(url)\n",
    "    try:\n",
    "        data = response.json()\n",
    "        data = data[0]\n",
    "        lat = data['lat']\n",
    "        lon = data['lon']\n",
    "        # the coordinates are to be save as rounded to x.00 or x.25 or x.50 or x.75\n",
    "        lat = round(float(lat) * 4) / 4\n",
    "        lon = round(float(lon) * 4) / 4\n",
    "        coordinates_list.append([place, lat, lon])\n",
    "        print(f\"Coordinates for {place} are {lat}, {lon}\")\n",
    "    except:\n",
    "        print(f\"Error getting coordinates for {place}\")\n",
    "\n",
    "# add the coordinates to the dataframe\n",
    "coordinates = pd.DataFrame(coordinates_list, columns=['Place', 'Latitude', 'Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "combined_data = pd.read_csv('combined_data.csv')\n",
    "\n",
    "# get the unique latitudes and longitudes combinations\n",
    "lat_lon = combined_data[['Latitude', 'Longitude']].drop_duplicates()\n",
    "\n",
    "# for each latitude and longitude in the combined data, get the place by comparing the latitude and longitude with the coordinates in the coordinates data\n",
    "places = []\n",
    "for index, row in lat_lon.iterrows():\n",
    "    lat = row['Latitude']\n",
    "    lon = row['Longitude']\n",
    "    # if place is found, add it to the list of places\n",
    "    if len(coordinates[(coordinates['Latitude'] == lat) & (coordinates['Longitude'] == lon)]) > 0:\n",
    "        place = coordinates[(coordinates['Latitude'] == lat) & (coordinates['Longitude'] == lon)]['Place'].values[0]\n",
    "        places.append(place)\n",
    "    else:\n",
    "        places.append('Unknown')\n",
    "# add the places to the combined data\n",
    "lat_lon['Place'] = places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv('combined_data.csv')\n",
    "coordinates = lat_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the two dataframes on longitude and latitude\n",
    "joined_data = combined_data.join(coordinates.set_index(\n",
    "    ['Longitude', 'Latitude']), on=['Longitude', 'Latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.value_counts('Place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows with unknown place\n",
    "joined_data = joined_data[joined_data['Place'] != 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_data['Season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the rows where the season value is Total\n",
    "production_data = production_data[production_data['Season'] != 'Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make another column in combined_data to store the year of the date\n",
    "joined_data['Year'] = pd.DatetimeIndex(joined_data['Date']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first extract first 4 characters of the date\n",
    "production_data['Year'] = production_data['Date'].astype(str).str[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the year of production data to integer\n",
    "production_data['Year'] = production_data['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the two dataframes on the year column and place column\n",
    "merged_data = pd.merge(joined_data, production_data, on=['Year', 'Place'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change format of Date_x which is in string format DD-MM-YYYY to datetime\n",
    "df['Date_x'] = pd.to_datetime(df['Date_x'], format='%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Date_y column\n",
    "df = df.drop(columns=['Date_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim white spaces from Season column\n",
    "df['Season'] = df['Season'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Season'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a place and year where the season value is Kharif, delete the rows where the date_x's month is 11, 12, 1, 2, 3, 4, 5\n",
    "df = df[~((df['Season'] == 'Kharif') & (\n",
    "    df['Date_x'].dt.month.isin([11, 12, 1, 2, 3, 4, 5])))]\n",
    "\n",
    "# for a place and year where the season value is Rabi, delete the rows where the date_x's month is 4 5 6 7 8 9\n",
    "df = df[~((df['Season'] == 'Rabi') & (\n",
    "    df['Date_x'].dt.month.isin([4, 5, 6, 7, 8, 9])))]\n",
    "\n",
    "# for a place and year where the season value is winter, delete the rows where the date_x's month is 3 4 5 6 7 8 9 10 11\n",
    "df = df[~((df['Season'] == 'Winter') & (\n",
    "    df['Date_x'].dt.month.isin([3, 4, 5, 6, 7, 8, 9, 10, 11])))]\n",
    "\n",
    "# for a place and year where the season value is summer, delete the rows where the date_x's month is 7, 8, 9, 10, 11, 12, 1, 2, 3\n",
    "df = df[~((df['Season'] == 'Summer') & (\n",
    "    df['Date_x'].dt.month.isin([7, 8, 9, 10, 11, 12, 1, 2, 3])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Latitude, Longitude, Area, Yield\n",
    "df = df.drop(['Latitude', 'Longitude', 'Yield', 'Date_x'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the data by Place, Year, Season and take the mean of the values\n",
    "df2 = df.groupby(['Place', 'Year', 'Season']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph between year and other weather parameters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.lineplot(x='Year', y='Temperature', data=df2)\n",
    "plt.title('Year vs Temperature')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.lineplot(x='Year', y='Relative_humidity', data=df2)\n",
    "plt.title('Year vs Humidity')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.lineplot(x='Year', y='Surface_net_solar_radiation', data=df2)\n",
    "plt.title('Year vs radiaion')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.lineplot(x='Year', y='Total_precipitation', data=df2)\n",
    "plt.title('Year vs rain')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to a csv file\n",
    "df2.to_csv('Onion_production_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".OpenHack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
